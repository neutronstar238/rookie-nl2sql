"""
M7 Acceptance Test: Dialog Clarification & Intent Disambiguation

Tests the ambiguity detection and question normalization capabilities.
"""
import sys
from pathlib import Path

project_root = Path(__file__).parent.parent
sys.path.insert(0, str(project_root))

from tools.ambiguity_detector import clarification_manager, AmbiguityDetector
from graphs.nodes.clarify_intent import clarify_intent_node
from graphs.state import NL2SQLState


def test_ambiguity_detection():
    """Test ambiguity detection with various question types."""
    
    print("\n" + "="*70)
    print("M7 Acceptance Test: Ambiguity Detection")
    print("="*70)
    
    test_cases = [
        {
            "id": 1,
            "question": "æŸ¥è¯¢æ‰€æœ‰å®¢æˆ·",
            "should_be_ambiguous": False,
            "expected_score_range": (0.0, 0.3),
            "description": "Clear question - no ambiguity"
        },
        {
            "id": 2,
            "question": "æŸ¥è¯¢æœ€è¿‘çš„è®¢å•",
            "should_be_ambiguous": True,
            "expected_score_range": (0.3, 1.0),
            "description": "Ambiguous time reference"
        },
        {
            "id": 3,
            "question": "æŸ¥è¯¢é”€å”®é¢å¾ˆå¤šçš„å®¢æˆ·",
            "should_be_ambiguous": True,
            "expected_score_range": (0.3, 1.0),
            "description": "Vague quantifier 'very many'"
        },
        {
            "id": 4,
            "question": "æŸ¥è¯¢å‰10ä¸ªå®¢æˆ·",
            "should_be_ambiguous": True,
            "expected_score_range": (0.2, 1.0),
            "description": "Missing sort criteria"
        },
        {
            "id": 5,
            "question": "ç»Ÿè®¡æ¯ä¸ªå›½å®¶çš„å®¢æˆ·æ•°é‡",
            "should_be_ambiguous": False,
            "expected_score_range": (0.0, 0.3),
            "description": "Clear aggregation query"
        },
        {
            "id": 6,
            "question": "æŸ¥è¯¢ä»·æ ¼é«˜çš„äº§å“",
            "should_be_ambiguous": True,
            "expected_score_range": (0.3, 1.0),
            "description": "Ambiguous 'high' threshold"
        },
        {
            "id": 7,
            "question": "æŸ¥è¯¢2024å¹´1æœˆé”€å”®é¢è¶…è¿‡1000çš„å®¢æˆ·",
            "should_be_ambiguous": False,
            "expected_score_range": (0.0, 0.3),
            "description": "Specific criteria - clear"
        },
        {
            "id": 8,
            "question": "æŸ¥è¯¢å®¢æˆ·è®¢å•",
            "should_be_ambiguous": True,
            "expected_score_range": (0.2, 1.0),
            "description": "Multiple interpretations"
        },
        {
            "id": 9,
            "question": "ç»Ÿè®¡æ€»æ•°",
            "should_be_ambiguous": True,
            "expected_score_range": (0.2, 1.0),
            "description": "Missing aggregation field"
        },
        {
            "id": 10,
            "question": "æ˜¾ç¤ºé”€å”®é¢å‰5çš„å®¢æˆ·æŒ‰æ—¶é—´æ’åº",
            "should_be_ambiguous": False,
            "expected_score_range": (0.0, 0.3),
            "description": "Clear with sort criteria"
        },
    ]
    
    detector = AmbiguityDetector()
    passed = 0
    failed = 0
    
    for tc in test_cases:
        print(f"\n### æµ‹è¯•ç”¨ä¾‹ {tc['id']}: {tc['description']} ###")
        print(f"Question: {tc['question']}")
        
        result = detector.detect_ambiguity(tc['question'])
        
        # Check ambiguity detection
        is_ambiguous = result['is_ambiguous']
        score = result['ambiguity_score']
        
        print(f"Is Ambiguous: {is_ambiguous} (expected: {tc['should_be_ambiguous']})")
        print(f"Ambiguity Score: {score:.2f} (expected range: {tc['expected_score_range']})")
        
        # Validation
        score_in_range = tc['expected_score_range'][0] <= score <= tc['expected_score_range'][1]
        ambiguity_matches = is_ambiguous == tc['should_be_ambiguous'] or score_in_range
        
        if ambiguity_matches and score_in_range:
            print(f"âœ“ PASS")
            passed += 1
        else:
            print(f"âœ— FAIL")
            failed += 1
        
        if result['clarification_questions']:
            print(f"Clarifications: {result['clarification_questions'][:2]}")
        
        if result['normalized_question']:
            print(f"Normalized: {result['normalized_question']}")
    
    print("\n" + "="*70)
    print(f"é€šè¿‡: {passed}/{len(test_cases)}")
    print(f"å¤±è´¥: {failed}/{len(test_cases)}")
    print(f"é€šè¿‡ç‡: {passed/len(test_cases)*100:.1f}%")
    print("="*70)
    
    return passed >= len(test_cases) * 0.9  # 90% pass rate


def test_normalization():
    """Test question normalization capabilities."""
    
    print("\n" + "="*70)
    print("M7 Acceptance Test: Question Normalization")
    print("="*70)
    
    test_cases = [
        {
            "id": 1,
            "question": "æŸ¥è¯¢æœ€è¿‘çš„è®¢å•",
            "should_normalize": True,
            "expected_contains": "30å¤©",
            "description": "Normalize 'recent' to specific days"
        },
        {
            "id": 2,
            "question": "æŸ¥è¯¢é”€å”®é¢å¾ˆå¤šçš„å®¢æˆ·",
            "should_normalize": True,
            "expected_contains": "100",
            "description": "Normalize 'many' to specific number"
        },
        {
            "id": 3,
            "question": "æŸ¥è¯¢æ‰€æœ‰å®¢æˆ·",
            "should_normalize": False,
            "expected_contains": None,
            "description": "Clear question needs no normalization"
        },
        {
            "id": 4,
            "question": "æŸ¥è¯¢å¤§é‡äº§å“",
            "should_normalize": True,
            "expected_contains": "1000",
            "description": "Normalize 'large amount'"
        },
    ]
    
    manager = clarification_manager
    passed = 0
    failed = 0
    
    for tc in test_cases:
        print(f"\n### æµ‹è¯•ç”¨ä¾‹ {tc['id']}: {tc['description']} ###")
        print(f"Original: {tc['question']}")
        
        result = manager.check_and_clarify(tc['question'])
        normalized = result['normalized_question']
        
        print(f"Normalized: {normalized}")
        
        # Validation
        was_normalized = normalized != tc['question']
        contains_expected = tc['expected_contains'] in normalized if tc['expected_contains'] else True
        
        if tc['should_normalize']:
            if was_normalized and contains_expected:
                print(f"âœ“ PASS - Normalized correctly")
                passed += 1
            else:
                print(f"âœ— FAIL - Expected normalization")
                failed += 1
        else:
            if not was_normalized:
                print(f"âœ“ PASS - No normalization needed")
                passed += 1
            else:
                print(f"âœ— FAIL - Unexpected normalization")
                failed += 1
    
    print("\n" + "="*70)
    print(f"é€šè¿‡: {passed}/{len(test_cases)}")
    print(f"å¤±è´¥: {failed}/{len(test_cases)}")
    print(f"é€šè¿‡ç‡: {passed/len(test_cases)*100:.1f}%")
    print("="*70)
    
    return passed >= len(test_cases) * 0.9


def test_clarify_node():
    """Test the clarify intent node integration."""
    
    print("\n" + "="*70)
    print("M7 Acceptance Test: Clarify Intent Node")
    print("="*70)
    
    test_cases = [
        {
            "id": 1,
            "question": "æŸ¥è¯¢æœ€è¿‘çš„è®¢å•",
            "should_need_clarification": True,
            "should_normalize": True,
        },
        {
            "id": 2,
            "question": "æŸ¥è¯¢æ‰€æœ‰å®¢æˆ·",
            "should_need_clarification": False,
            "should_normalize": False,
        },
        {
            "id": 3,
            "question": "æŸ¥è¯¢é”€å”®é¢å¾ˆå¤šçš„å®¢æˆ·",
            "should_need_clarification": True,
            "should_normalize": True,
        },
    ]
    
    passed = 0
    failed = 0
    
    for tc in test_cases:
        print(f"\n### æµ‹è¯•ç”¨ä¾‹ {tc['id']} ###")
        print(f"Question: {tc['question']}")
        
        state: NL2SQLState = {
            "question": tc['question'],
            "session_id": f"test_{tc['id']}",
            "timestamp": None,
            "intent": None,
            "candidate_sql": None,
            "sql_generated_at": None,
            "execution_result": None,
            "executed_at": None,
            "schema": None,
            "schema_loaded_at": None,
            "validation_result": None,
            "validated_at": None,
            "sandbox_check": None,
            "sandbox_checked_at": None,
            "rag_evidence": None,
            "rag_retrieved_at": None,
            "clarification_needed": None,
            "clarification_questions": None,
            "ambiguity_score": None,
            "normalized_question": None,
            "clarified_at": None,
            "join_complexity": None,
            "suggested_templates": None,
            "template_matched_at": None,
        }
        
        result = clarify_intent_node(state)
        
        # Validate results
        needs_clarification = result.get('clarification_needed', False)
        was_normalized = result.get('normalized_question') != tc['question']
        
        print(f"Needs Clarification: {needs_clarification} (expected: {tc['should_need_clarification']})")
        print(f"Was Normalized: {was_normalized} (expected: {tc['should_normalize']})")
        
        if result.get('clarification_needed'):
            # For ambiguous questions, we should either normalize or provide clarification questions
            has_output = was_normalized or (result.get('clarification_questions') and len(result['clarification_questions']) > 0)
            if has_output:
                print(f"âœ“ PASS")
                passed += 1
            else:
                print(f"âœ— FAIL - No clarification output")
                failed += 1
        else:
            # For clear questions, should not need clarification
            if not needs_clarification:
                print(f"âœ“ PASS")
                passed += 1
            else:
                print(f"âœ— FAIL - Unexpected clarification needed")
                failed += 1
    
    print("\n" + "="*70)
    print(f"é€šè¿‡: {passed}/{len(test_cases)}")
    print(f"å¤±è´¥: {failed}/{len(test_cases)}")
    print(f"é€šè¿‡ç‡: {passed/len(test_cases)*100:.1f}%")
    print("="*70)
    
    return passed >= len(test_cases) * 0.9


if __name__ == "__main__":
    """Run all M7 acceptance tests."""
    
    print("\n" + "="*80)
    print("M7 æ¨¡å—éªŒæ”¶æµ‹è¯•")
    print("="*80)
    
    results = []
    
    # Test 1: Ambiguity Detection
    results.append(("Ambiguity Detection", test_ambiguity_detection()))
    
    # Test 2: Question Normalization
    results.append(("Question Normalization", test_normalization()))
    
    # Test 3: Clarify Node Integration
    results.append(("Clarify Node Integration", test_clarify_node()))
    
    # Summary
    print("\n" + "="*80)
    print("æµ‹è¯•æ€»ç»“")
    print("="*80)
    
    for name, passed in results:
        status = "âœ“ PASS" if passed else "âœ— FAIL"
        print(f"{name}: {status}")
    
    all_passed = all(r[1] for r in results)
    
    if all_passed:
        print("\nğŸ‰ M7 éªŒæ”¶æµ‹è¯•å…¨éƒ¨é€šè¿‡ï¼")
    else:
        print("\nâš ï¸ éƒ¨åˆ†æµ‹è¯•æœªé€šè¿‡ï¼Œè¯·æ£€æŸ¥ã€‚")
    
    print("="*80)
